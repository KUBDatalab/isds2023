{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ec8d0279-4ba4-4da6-ba0c-509075ddc584",
   "metadata": {},
   "source": [
    "Created by Daniel Pryn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810dd8f7-1e82-452f-b734-7624f51c0351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b08b873-3ecd-449b-b10d-28710d7f10cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_file.csv' with the actual path to your CSV file\n",
    "input_fp = Path.cwd() / 'tidy_data' # path of files to be found\n",
    "\n",
    "output_fp = Path.cwd() / 'unique_data' # output path of files generated\n",
    "# Use the Path object to actually create the subfolder\n",
    "Path.mkdir(output_fp, exist_ok=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7ac4901-e0e3-4e47-bc8b-fdc01428e193",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Not working:\n",
    "\n",
    "def find_matching_rows(df):\n",
    "    #find every sale with same date_of_sale, purchase_amount, zip_code, and housing_type\n",
    "    grouped = df.groupby(['date_of_sale', 'purchase_amount', 'zip_code', 'housing_type'])\n",
    "    matching_indices = []\n",
    "\n",
    "    #for 'Ejerlejlighed' the 'address' should start with the same three letters, i.e., be on the same street\n",
    "    for _, group in grouped:\n",
    "        if len(group) > 1:\n",
    "            if group['housing_type'].iloc[0] == 'Ejerlejlighed':\n",
    "                address_prefix = group['address'].str[:3]\n",
    "                if address_prefix.nunique() == 1:\n",
    "                    matching_indices.extend(group.index.tolist())\n",
    "            #for other sales we accept different addresses, as some double sales take place around corners\n",
    "            else:\n",
    "                matching_indices.extend(group.index.tolist())\n",
    "\n",
    "    return matching_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862452f5-e2d7-4ccf-91a9-4bfb515d9f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_rows(df):\n",
    "    grouped = df.groupby(['date_of_sale', 'purchase_amount', 'zip_code'])\n",
    "    matching_indices = []\n",
    "\n",
    "    for _, group in grouped:\n",
    "        if len(group) > 1:\n",
    "            matching_indices.extend(group.index.tolist())\n",
    "\n",
    "    return matching_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b0223d-64d1-4cfa-8435-bc53e0fef1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Iterate through log files in the folder\n",
    "for filename in sorted(os.listdir(input_fp)): #Alternative: for filename in tqdm.tqdm(sorted(os.listdir(input_fp))):\n",
    "    if filename.startswith('tidy_sales_1992_2022_') and filename.endswith('.csv'):\n",
    "        df = pd.read_csv(input_fp/filename, low_memory=False) # read the CSV file into a DataFrame\n",
    "        #print(df.shape)\n",
    "        matching_indices = find_matching_rows(df)\n",
    "        matching_df = df[df.index.isin(matching_indices)]\n",
    "        unique_matching_indices = list(set(matching_indices))\n",
    "\n",
    "        # List of index numbers to exclude\n",
    "        index_numbers_to_exclude = unique_matching_indices\n",
    "        \n",
    "        # Create a new DataFrame excluding rows with specified index numbers\n",
    "        new_df = df[~df.index.isin(index_numbers_to_exclude)]\n",
    "        \n",
    "        # Rename and save the new DataFrame to a CSV file without index numbers\n",
    "        output_filename = filename.replace('tidy_', 'unique_')  # Replace 'tidy_' with 'unique_' in filename\n",
    "        new_df.to_csv(f'{output_fp}/{output_filename}', index=False)\n",
    "\n",
    "        print(f'Number of rows in {filename}: {len(df)}')\n",
    "        print(f'Number of matching rows: {len(matching_df)}')\n",
    "        print(f'Number of unique rows: {len(new_df)}')\n",
    "        print()\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'Runtime: {elapsed_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cef337b-e669-4500-b258-abc0e0f16772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
